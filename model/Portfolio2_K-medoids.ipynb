{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I try solving the cold start problem in the recommendation engine by exploring how the clusters behave in this dataset and build functions to deploy the cluster process in the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../data/portfolio2_ETL.csv does not exist: '../data/portfolio2_ETL.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e3214f2c31fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data/portfolio2_ETL.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mportfolio2_ID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mportfolio2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mportfolio2_ID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-e3214f2c31fb>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m     20\u001b[0m     '''\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricardo_2\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricardo_2\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricardo_2\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricardo_2\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ricardo_2\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ../data/portfolio2_ETL.csv does not exist: '../data/portfolio2_ETL.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from scipy import stats\n",
    "import gower\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import silhouette_score\n",
    "import random\n",
    "import umap as umap\n",
    "\n",
    "\n",
    "def load_data(filepath):\n",
    "    '''takes in the file path where the data is store and returns a pandas dataframe.\n",
    "    filepath must be entered as a string\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    return df;\n",
    "\n",
    "filepath = '../data/portfolio2_ETL.csv'\n",
    "portfolio2_ID = load_data(filepath)\n",
    "\n",
    "portfolio2 = portfolio2_ID.drop(columns=['id'])\n",
    "portfolio2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of non bolean columns taken from the market database\n",
    "non_bolean_cols = ['idade_empresa_anos',\n",
    " 'idade_maxima_socios',\n",
    " 'idade_media_socios',\n",
    " 'idade_minima_socios',\n",
    " 'qt_filiais',\n",
    " 'qt_socios',\n",
    " 'qt_socios_st_regular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_col(df_transform,cols):\n",
    "    '''\n",
    "    Input \n",
    "    Takes in a dataframe and a column being a continuous feature to normalize (min =0, and max =1)\n",
    "    \n",
    "    Output\n",
    "    New dataframe with the column passed normalized\n",
    "    '''\n",
    "    mmsc = MinMaxScaler()\n",
    "    for col in cols:\n",
    "        var_cont = df_transform.loc[:,col].values.reshape(-1,1)\n",
    "        var_cont_standarized = mmsc.fit_transform(var_cont)\n",
    "        df_transform.loc[:,col] = var_cont_standarized\n",
    "    return df_transform;\n",
    "\n",
    "\n",
    "\n",
    "#Keeping the same rule applied to the market, which is normalization over standarization in iteration 0\n",
    "portfolio2 = min_max_col(portfolio2,non_bolean_cols)\n",
    "portfolio2[non_bolean_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissimilarity_matrix = gower.gower_matrix(portfolio2)\n",
    "dissimilarity_matrix.shape, dissimilarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random initial medoids\n",
    "initial_medoids = [1, 10, 50, 100]\n",
    "# create K-Medoids algorithm for processing distance matrix instead of points\n",
    "kmedoids_instance = kmedoids(dissimilarity_matrix, initial_medoids, data_type='distance_matrix')\n",
    "# run cluster analysis and obtain results\n",
    "kmedoids_instance.process()\n",
    "\n",
    "clusters = kmedoids_instance.get_clusters()\n",
    "\n",
    "medoids = kmedoids_instance.get_medoids()\n",
    "\n",
    "medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmedoids_instance.get_cluster_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusters[0]), len(clusters[1]), len(clusters[2]), len(clusters[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.Series(0,index=range(0,portfolio2.shape[0]))\n",
    "for i in range (0,len(clusters)):\n",
    "    for n in range (0,len(clusters[i])):\n",
    "        index = clusters[i][n]\n",
    "        labels.iloc[index] = i\n",
    "\n",
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(dissimilarity_matrix, labels, metric='precomputed', sample_size=None, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dissimilarity_matrix\n",
    "\n",
    "# Get silhouette samples\n",
    "silhouette_vals = silhouette_samples(X, labels,metric='precomputed')\n",
    "# Silhouette plot\n",
    "fig, (ax1) = plt.subplots(1)\n",
    "fig.set_size_inches(18, 7)\n",
    "    \n",
    "y_ticks = []\n",
    "y_lower, y_upper = 0, 0\n",
    "for i, cluster in enumerate(np.unique(labels)):\n",
    "    cluster_silhouette_vals = silhouette_vals[labels == cluster]\n",
    "    cluster_silhouette_vals.sort()\n",
    "    y_upper += len(cluster_silhouette_vals)\n",
    "    ax1.barh(range(y_lower, y_upper), cluster_silhouette_vals, edgecolor='none', height=1)\n",
    "    ax1.text(-0.03, (y_lower + y_upper) / 2, str(i + 1))\n",
    "    y_lower += len(cluster_silhouette_vals)\n",
    "\n",
    "    # Get the average silhouette score and plot it\n",
    "avg_score = np.mean(silhouette_vals)\n",
    "ax1.axvline(avg_score, linestyle='--', linewidth=2, color='green')\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xlim([-0.1, 1])\n",
    "ax1.set_xlabel('Silhouette coefficient values')\n",
    "ax1.set_ylabel('Cluster labels')\n",
    "ax1.set_title('Silhouette plot for the various clusters', y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medoids_per_k = []\n",
    "k_scores = []\n",
    "wss = []\n",
    "random.seed(42)\n",
    "for i, k in enumerate([2, 3, 4, 5, 6, 7]):\n",
    "    fig, (ax1) = plt.subplots(1)\n",
    "    fig.set_size_inches(18, 7)\n",
    "    \n",
    "    initial_medoids_km = random.sample(range(1, 266), k)\n",
    "    # Run the Kmeans algorithm\n",
    "    km = kmedoids(dissimilarity_matrix, initial_medoids_km, data_type='distance_matrix')\n",
    "    km.process()\n",
    "    #centroids = kmedoids_instance.get_medoids()\n",
    "    clusters_km = km.get_clusters()\n",
    "    medoids_km = km.get_medoids()\n",
    "    medoids_per_k.append(medoids_km)\n",
    "    labels_km = pd.Series(0,index=range(0,portfolio2.shape[0]))\n",
    "    for i in range (0,len(clusters_km)):\n",
    "        for n in range (0,len(clusters_km[i])):\n",
    "            index = clusters_km[i][n]\n",
    "            labels_km.iloc[index] = i\n",
    "    \n",
    "    clusters_distances = []\n",
    "    for n in range (0,len(clusters_km)):\n",
    "        clusters_distances.append(X[medoids_km[n]][labels_km[labels_km == n].index].sum())\n",
    "    \n",
    "    wss.append(sum(clusters_distances))\n",
    "\n",
    "    # Get silhouette samples\n",
    "    silhouette_vals = silhouette_samples(X, labels_km,metric='precomputed')\n",
    "\n",
    "    # Silhouette plot\n",
    "    y_ticks = []\n",
    "    y_lower, y_upper = 0, 0\n",
    "    for i, cluster in enumerate(np.unique(labels_km)):\n",
    "        cluster_silhouette_vals = silhouette_vals[labels_km == cluster]\n",
    "        cluster_silhouette_vals.sort()\n",
    "        y_upper += len(cluster_silhouette_vals)\n",
    "        ax1.barh(range(y_lower, y_upper), cluster_silhouette_vals, edgecolor='none', height=1)\n",
    "        ax1.text(-0.03, (y_lower + y_upper) / 2, str(i + 1))\n",
    "        y_lower += len(cluster_silhouette_vals)\n",
    "\n",
    "    # Get the average silhouette score and plot it\n",
    "    \n",
    "    avg_score = np.mean(silhouette_vals)\n",
    "    k_scores.append(avg_score)\n",
    "    ax1.axvline(avg_score, linestyle='--', linewidth=2, color='green')\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_xlabel('Silhouette coefficient values')\n",
    "    ax1.set_ylabel('Cluster labels')\n",
    "    ax1.set_title('Silhouette plot for the various clusters', y=1.02);\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.3)\n",
    "\n",
    "plt.figure(figsize=(24,10))\n",
    "plt.plot(list(range(2, 8)), wss,marker='o', linewidth=3, markersize=10)\n",
    "\n",
    "plt.title('The Elbow Method') \n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Within Sum of Squares\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_umap(data, n_neighbors, min_dist, n_components, title, metric='euclidean'):\n",
    "    fit = umap.UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_components=n_components,\n",
    "        metric=metric,\n",
    "        random_state = 42\n",
    "    )\n",
    "    u = fit.fit_transform(data);\n",
    "    fig = plt.figure(figsize=(24,10))\n",
    "    if n_components == 1:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], range(len(u)))\n",
    "    if n_components == 2:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], u[:,1])\n",
    "    if n_components == 3:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(u[:,0], u[:,1], u[:,2], s=100)\n",
    "    plt.title(title, fontsize=18)\n",
    "    \n",
    "title = 'UMAP projection of portfolio2'    \n",
    "draw_umap(portfolio2,14,0.1,3,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This visualization is merily to generate a plot to show how are our clusters distributed.\n",
    "UMAP doesn't have the gower distance in-built, but it supports custom distances, \n",
    "so a function had to be written to show how it actually behaved with the distance used to build the clusters.\n",
    "Instead we'll look at the plot with the manhattan and dice distances which are the distances used in the gower distance.'''\n",
    "\n",
    "fit = umap.UMAP(n_neighbors=14,min_dist=0.1,n_components=3,metric='dice', random_state=42)\n",
    "p2_umap = fit.fit_transform(portfolio2)\n",
    "\n",
    "# Visualising the clusters\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[clusters[0], 0], y=p2_umap[clusters[0], 1], z=p2_umap[clusters[0], 2], name='Cluster 1', mode='markers'))\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[clusters[1], 0], y=p2_umap[clusters[1], 1], z=p2_umap[clusters[1], 2], name='Cluster 2', mode='markers'))\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[clusters[2], 0], y=p2_umap[clusters[2], 1], z=p2_umap[clusters[2], 2], name='Cluster 3', mode='markers'))\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[clusters[3], 0], y=p2_umap[clusters[3], 1], z=p2_umap[clusters[3], 2], name='Cluster 4', mode='markers'))\n",
    "#comment the lines if you chose less clusters\n",
    "#add more lines if you chose more clusters\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[medoids,0], y=p2_umap[medoids,1],z=p2_umap[medoids,2], name='Centroids', \n",
    "                         mode='markers', marker_color=\"rgb(255,255,0)\", marker=dict(size=16)))\n",
    "\n",
    "fig.update_layout(title='Clusters with the Dice Distance')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = umap.UMAP(n_neighbors=14,min_dist=0.1,n_components=3,metric='manhattan', random_state=42)\n",
    "p2_umap = fit.fit_transform(portfolio2)\n",
    "\n",
    "# Visualising the clusters\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[clusters[0], 0], y=p2_umap[clusters[0], 1], z=p2_umap[clusters[0], 2], name='Cluster 1', mode='markers'))\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[clusters[1], 0], y=p2_umap[clusters[1], 1], z=p2_umap[clusters[1], 2], name='Cluster 2', mode='markers'))\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[clusters[2], 0], y=p2_umap[clusters[2], 1], z=p2_umap[clusters[2], 2], name='Cluster 3', mode='markers'))\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[clusters[3], 0], y=p2_umap[clusters[3], 1], z=p2_umap[clusters[3], 2], name='Cluster 4', mode='markers'))\n",
    "#comment the lines if you chose less clusters\n",
    "#add more lines if you chose more clusters\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=p2_umap[medoids,0], y=p2_umap[medoids,1],z=p2_umap[medoids,2], name='Centroids', \n",
    "                         mode='markers', marker_color=\"rgb(255,255,0)\", marker=dict(size=16)))\n",
    "\n",
    "fig.update_layout(title='Clusters with the Manhattan Distance')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
